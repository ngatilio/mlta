url,title,comments,state,created_at,closed_at
https://api.github.com/repos/eclipse/deeplearning4j/issues/9471,"b'Dependency org.apache.commons:commons-compress, leading to CVE problem'","[b'@agibsonccc \r\nCould please help me check this issue?\r\nMay I pull a request to fix it?\r\nThanks again.', b'@CVEDetect yes please do. Happy to review.']",closed,2021-10-04 02:43:45,2021-12-02 21:38:58
https://api.github.com/repos/eclipse/deeplearning4j/issues/9460,b'Receiving a NullPointerException when train bert on ner task',"[b""@benbenwt thanks for posting, I just want to acknowledge that we saw this. My initial thoughts based on the stack trace is there's some sort of a disconnect in the graph if it's missing execution steps. Do you have the original graph you used to import it? Also, is this based on the older import api or the new one?  If you don't know what I'm referencing, please see more here: https://deeplearning4j.konduit.ai/samediff/explanation/model-import-framework Thanks!"", b""I  don't  have  the  original  graph .Actually\xef\xbc\x8cI got  this  bert  model  file  with  your  help  a  few  days  ago.But  I  stop  following  this  work  for  a  while  for  some  reasons.You  post the converted model for me,So  I  work  on  the  flatbuffers   model  directly.\r\n\r\nAnd  this  is  the  community  link:\r\nhttps://community.konduit.ai/t/some-error-happened-when-i-importfrozentf-by-samediffi/1552/5\r\n\r\nthis  is  the  issue  link:\r\nhttps://github.com/eclipse/deeplearning4j/issues/9420\r\n"", b""@benbenwt just looking at this again a bit, did you try ensuring your version was the latest? Sorry to ask a redundant question, this was just something I noticed.\r\n\r\nUpdate: Ran this with latest and I run in to a different issue. It's complaining about the gradient not being calculated for  your bias...there's something wrong with the graph surgery. Let me get back to you after a bit."", b'Yes,I try this with latest and I got a new issue.But it`s about ""the op named mask "" .I do not understand this error,because mask is the input of bert instead of output.This is  the  log.\r\n```\r\nException in thread ""main"" java.lang.IllegalStateException: Samediff output op named mask did not have any ops associated with it.\r\n\tat org.nd4j.autodiff.samediff.internal.AbstractSession.getExecStepForVar(AbstractSession.java:706)\r\n\tat org.nd4j.autodiff.samediff.internal.AbstractSession.addDependenciesForOp(AbstractSession.java:665)\r\n\tat org.nd4j.autodiff.samediff.internal.AbstractSession.updateDescendantDeps(AbstractSession.java:596)\r\n\tat org.nd4j.autodiff.samediff.internal.AbstractSession.output(AbstractSession.java:477)\r\n\tat org.nd4j.autodiff.samediff.internal.TrainingSession.trainingIteration(TrainingSession.java:127)\r\n\tat org.nd4j.autodiff.samediff.SameDiff.fitHelper(SameDiff.java:1714)\r\n\tat org.nd4j.autodiff.samediff.SameDiff.fit(SameDiff.java:1570)\r\n\tat org.nd4j.autodiff.samediff.SameDiff.fit(SameDiff.java:1453)\r\n\tat com.wt.utils.TestMaster.train(TestMaster.java:124)\r\n\tat com.wt.utils.TestMaster.main(TestMaster.java:102)\r\n```', b'I may find something  odd.I got an error if I call summary function.\r\n```\r\n        File f=new File(""D:\\\\deeplearning4j-examples\\\\mydownload\\\\output-bert\\\\output-bert.fb"");\r\n        SameDiff sd= SameDiff.load(f,true);\r\n        System.out.println(sd.summary());\r\n```\r\n\r\n```\r\nException in thread ""main"" java.lang.UnsupportedOperationException: Cannot get array for ARRAY type SDVariable - use SDVariable.exec or SameDiff.output instead\r\n\tat org.nd4j.autodiff.samediff.SameDiff.getArrForVarName(SameDiff.java:747)\r\n\tat org.nd4j.autodiff.samediff.SameDiff.summary(SameDiff.java:5591)\r\n\tat com.wt.utils.TestMaster.getBertModel(TestMaster.java:155)\r\n\tat com.wt.utils.TestMaster.train(TestMaster.java:105)\r\n\tat com.wt.utils.TestMaster.main(TestMaster.java:102)\r\n```', b'Of note here: you have to call exec. An ARRAY type variable in samediff is a computed result. You can see a summary after feeding it some dummy output.', b""I fixed the summary call a while back. We've imported a few BERT models now so I don't think there should be a problem. I will close this.""]",closed,2021-09-27 09:39:17,2021-12-02 01:48:39
https://api.github.com/repos/eclipse/deeplearning4j/issues/9179,b'snakeyaml is showing up as HIGH critical vulnerability',[],closed,2021-02-08 15:11:20,2021-04-26 05:39:36
https://api.github.com/repos/eclipse/deeplearning4j/issues/9083,b'Shaded snakeyaml version affected by vulnerability',[b'Closing in favor of: https://github.com/eclipse/deeplearning4j/issues/9179'],closed,2020-09-07 09:14:25,2021-04-15 05:47:47
https://api.github.com/repos/eclipse/deeplearning4j/issues/9138,b'jackson-databind vulnerability',[],closed,2020-12-09 15:09:47,2021-04-01 08:16:42
https://api.github.com/repos/eclipse/deeplearning4j/issues/7789,b'fix: pom.xml to reduce vulnerabilities',[],closed,2019-05-27 16:06:03,2019-05-27 16:06:37
https://api.github.com/repos/eclipse/deeplearning4j/issues/6655,b'Upgrade Shaded Jackson version',"[b""For what it's worth, this is a major problem for us.  The critical security vulnerabilities in the older Jackson libs show up in security scans, and large customers with mature IT security processes see these vulnerabilities and require us to remove or mitigate them.  Is it possible to attest that as long as any JSON being read is valid and comes from trusted sources, the vulnerabilities are mitigated?"", b""@ejschoen This is something we've been meaning to get to for a while.\r\nThanks for flagging it again, we'll talk internally and post here once we have something more to share.\r\n\r\nNow, I can't see how our use of Jackson (which is basically limited to deserializing neural network configurations, NDArrays and schemas/transforms in DataVec) could lead to vulnerabilities if used in a standard way, if (a) you know and trust the source of the model/JSON, and/or (b) you control the classpath.\r\n\r\nThat said, I'm not able to make any claims that any particular CVE is/isn't impossible given our current use of Jackson, without looking at the specifics. And I'd rather spend that time upgrading the library version instead (in the case of the shaded Jackson dependency, it's a matter of when, not if)."", b'Fixed here: https://github.com/eclipse/deeplearning4j/pull/8098\r\nWill be merged soon.']",closed,2018-10-31 23:48:22,2019-08-30 04:35:28
https://api.github.com/repos/eclipse/deeplearning4j/issues/6652,b'Why is jackson being shadowed?',"[b""No. We integrate with god knows how many libraries all with their own versions of jackson. About 3 to 4 years of code > `1 million lines of code is the reason for that.  If you're *that* concerned, we have to navigate backwards compatibility and the like. We're happy to upgrade. We're going to do it when the ROI is there and done pragmatically though."", b""Thanks @agibsonccc for your quick reply.\r\n\r\nI think that anyone who cares about the security of their sofware at a minimal level will be that concerned and depending on nd4j will not be an option for them if it's complicated to upgrade 4th party dependencies in case of CVEs.\r\n\r\n> We're going to do it when the ROI is there and done pragmatically though.\r\n\r\nI don't think I understand what you mean with that, would you be so kind and explain?\r\n\r\nThanks!"", b'https://github.com/deeplearning4j/deeplearning4j/issues/6655\r\n\r\nI agree that this is something we should revisit. But Adam has alluded to, upgrading the version is not a trivial task, requiring testing and changes across multiple libraries.', b'Thank you @AlexDBlack ', b'This thread has been automatically locked since there has not been any recent activity after it was closed. Please open a new issue for related bugs.\n']",closed,2018-10-31 15:44:54,2018-10-31 15:48:01
