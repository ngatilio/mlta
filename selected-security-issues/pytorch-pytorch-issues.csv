url,title,comments,state,created_at,closed_at
,,,,,
https://api.github.com/repos/pytorch/pytorch/issues/50090,b'Torch native_layer_norm OP out-of-bounds access',"[b""Can't repro on master. Signature of `native_layer_norm` changed, but even accounting for that I get a correct error message:\r\n```\r\nIn [3]: import torch \r\n   ...: from torch import tensor \r\n   ...: torch.native_layer_norm(tensor([1.0,2,3,4,5]), (213,1),  tensor([1.0]), tensor([1.,2,3,4,5]),  5.280893892284248)                                                                                                                                                                         \r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-3-91e045ad1518> in <module>\r\n      2 from torch import tensor\r\n      3 torch.native_layer_norm(tensor([1.0,2,3,4,5]), (213,1), \r\n----> 4 tensor([1.0]), tensor([1.,2,3,4,5]),  5.280893892284248)\r\n\r\nRuntimeError: Expected weight to be of same shape as normalized_shape, but got weight of shape [1] and normalized_shape = [213, 1]\r\n\r\n```\r\nCurrent signature is \r\n```\r\nfunc: native_layer_norm(Tensor input, int[] normalized_shape, Tensor? weight, Tensor? bias, float eps) -> (Tensor, Tensor, Tensor)\r\n```\r\n""]",open,1/5/2021 8:19,
,,,,,
https://api.github.com/repos/pytorch/pytorch/issues/50037,b'Torch quantized_lstm_cell op out-of-bounds access',[],open,1/4/2021 10:35,
,,,,,
https://api.github.com/repos/pytorch/pytorch/issues/52596,b'pickle is a security issue',"[b'Related: https://github.com/pytorch/pytorch/issues/52181 ... One of my suggestions was supporting hdf5 for safe weights storage', b'It already has a clear warning in https://pytorch.org/docs/master/generated/torch.load.html:\r\n\r\n<img width=""506"" alt=""image"" src=""https://user-images.githubusercontent.com/98330/108752433-bb443480-7543-11eb-9e17-1a9149e64ab3.png"">\r\n\r\nDeprecating doesn\'t seem warranted; the Python pickle module itself (https://docs.python.org/3/library/pickle.html) has a similar warning. As does `numpy.load` (the issue is smaller there, but it exists and will remain with a docs warning).\r\n\r\nA good alternative does seem needed indeed. That part of the issue seems duplicate with gh-52181.', b'torch.hub.load doesn\'t have such a big clear notice + may be good it printed a UserWarning that\'s easier to notice (not everyone would check in docs these ""simple"" methods). + I also didn\'t see such big red warnings at model zoos like hugging face\r\n\r\na nightmare scenario: some ""cool"" recent model uploaded to hugging face by some malicious actors, publicized on twitter, and then gets backdoor access at research labs over the world... it must execute code, i propose to have some `this_is_dangerous_and_can_in_principle_execute_malicious = True` mandatory keyword argument to these code-executing methods, so that the user is actively aware of this', b"">It already has a clear warning in https://pytorch.org/docs/master/generated/torch.load.html:\r\n\r\nIt doesn't prevent people from using it for loading models and from storing models into this format.\r\n\r\n>i propose to have some this_is_dangerous_and_can_in_principle_execute_malicious = True mandatory keyword argument to these code-executing methods, so that the user is actively aware of this\r\n\r\nNot enough. Phasing out it is the only feasible way in long term. In short term the solution is to defuse pickle used and make it clear not only to devs of the software but also to users that they should blame the devs still using pickle. Such dangerous temporary solutions when introduced should have a clear deadline. Also IMHO it was a big mistake to introduce pickle into python at all."", b""cc @ailzhang for hub -- what do you think? Folks are concerned about who can post to hub and if downloaded models can contain viruses.\r\n\r\ncc @suo for package or deploy: I remember there was some discussion around unifying the serialization behavior of torch.save/load (and using zipfile serialization?). One of the things proposed in this issue is to change the serialization format for PyTorch. We probably don't want to go down the route of yet another serialization format here."", b'For zipfile - I hope it doesn\'t resort to good old pickle torch.load to handle loading of weights from inside the zipfile.\r\n\r\nIn my opinion, all existing frameworks, including TF / tfjs have screwed up weights serialization, so we already ended up with 10 different formats :( So adding another ""good"" one should not be a problem, if it is secure, performant and interoperable.', b'Also I wonder if huggingface does anything about verifying who submits models there. I think huggingface hub is now getting more popular than the slow-moving torchhub one', b""I don't think WHO sends the model is the main issue. If the models themselves can not be Turing-complete and a complex of a model + pytorch machinery by itself cannot be Turing complete and if models don't allow priveleged operations within computation graph, such as calling any API which effect is not simple computation, we are likely safe, if operations with numbers are implemented correctly (they can be not: https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3177 ).\r\n\r\nSo at first we should concentrate not on WHO can upload models, but on WHAT models can do. Authenticating models via digital signatures is clearly useful, but its effect will be very minor.\r\n\r\n The problem with models is that they are large, binary and hard to audit for humans. It won't help much to know that the model was published by huggingface, if we still don't trust huggingface and have no real reasons to trust them.\r\n\r\nAlso there are parties other than huggingface. Should we not to use their models because we don't trust them?\r\n\r\nSo we need not attribution in the first place, but a proof that any model cannot compromise integrity of a system and confidentiality of the information processed in it in some sensible threat model. So we trust not the persons issuing the models, but the beleif that our threat model is sensible.""]",open,2/22/2021 9:40,
,,,,,
https://api.github.com/repos/pytorch/pytorch/issues/32147,b'[iOS] Update Gemfile',[b'@xta0 merged this pull request in pytorch/pytorch@ecc349717261185c61110c38c83dff00edceaade.'],closed,1/14/2020 0:47,1/14/2020 22:54
