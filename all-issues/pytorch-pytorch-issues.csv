id,Title,Tag,State,Open Date,Close Date
71998,"b'Change xfail to skip for test_fn_fwgrad_bwgrad_cuda_{float64,complex128}'","['cla signed', 'ciflow/default']",open,2022-01-28T17:46:54Z,
71997,b'[Quant] Combined dispatch registration for max_pool1d & quantized_max_pool1d',"['cla signed', 'ciflow/default']",open,2022-01-28T17:38:41Z,
71996,b'Move torch._masked to torch.masked',"['cla signed', 'ciflow/default']",open,2022-01-28T16:57:29Z,
71995,b'Fix internal assert custom function when requires grad false',"['cla signed', 'ciflow/default']",open,2022-01-28T16:40:30Z,
71994,"b""TorchScript doesn't support `input` keyword argument""",['oncall: jit'],open,2022-01-28T16:33:44Z,
71993,b'Remove istft python functional wrapper',"['open source', 'cla signed', 'ciflow/default']",open,2022-01-28T16:22:44Z,
71992,"b'Revert ""[fix] max_pool1d: composite compliance (#70900)""'","['cla signed', 'ciflow/default']",open,2022-01-28T16:13:00Z,
71991,b'How to make LSTMClassifier Bidirectional?',[],closed,2022-01-28T16:03:23Z,2022-01-28T17:45:16Z
71990,b'Separated implementations for quantized & non-quantized tensors in in empty_like',"['cla signed', 'ciflow/default']",open,2022-01-28T15:54:26Z,
71989,b'Report the timing for shape inference and LT IR node creation',"['cla signed', 'ciflow/default']",open,2022-01-28T15:45:00Z,
71988,b'multiple PRs on pytorch are closed by push to unrelated branches such as pytorch-canary',['module: third_party'],open,2022-01-28T15:26:52Z,
71987,b'Improve autograd codegened automatic inplace formulas',"['module: performance', 'module: autograd', 'triaged', 'actionable']",open,2022-01-28T14:51:54Z,
71986,b'[SR] Eliminate op_name_ in ProcessedNode',"['oncall: jit', 'cla signed', 'ciflow/default']",open,2022-01-28T13:13:03Z,
71985,b'DOC: create 1.12 docs from a tag like v1.12.2rc1',"['open source', 'cla signed', 'ciflow/default']",open,2022-01-28T11:39:25Z,
71984,b'Implement `__ipow__`  to make it compatible with the Python Array API ',"['open source', 'cla signed', 'ciflow/default']",open,2022-01-28T11:19:01Z,
71983,b'Support `torch.broadcast_arrays` alias ',"['oncall: jit', 'open source', 'cla signed', 'ciflow/default']",open,2022-01-28T10:57:36Z,
71982,b'Avoid unnecessary copy of ExecutionPlan in operator()',"['oncall: jit', 'fb-exported', 'cla signed', 'ciflow/default']",open,2022-01-28T10:33:39Z,
71981,b'Skip meta device for test_svd_nan_error',"['open source', 'cla signed', 'ciflow/cuda']",closed,2022-01-28T08:37:21Z,2022-01-28T14:01:16Z
71980,b'Torch.tensor.sum() has severe precision issue even with a small amount of numbers with FP64',[],closed,2022-01-28T08:01:34Z,2022-01-28T09:31:29Z
71979,"b'[bug fix] for add_activation layer, mobilenetv2 is fixed'","['fb-exported', 'cla signed', 'ciflow/default', 'fx']",open,2022-01-28T06:39:24Z,
71978,b'from_blob / make_tensor support MemoryFormat',[],open,2022-01-28T06:18:58Z,
71977,"b""Skip gradient test that's silently killing CI""","['cla signed', 'ciflow/default']",open,2022-01-28T06:16:21Z,
71976,b'[WIP] size tracing in LTC',"['cla signed', 'ciflow/default']",open,2022-01-28T05:49:11Z,
71975,"b'PyTorch/XLA jobs are not being run on PR CI, even with ciflow/all'","['high priority', 'triage review', 'ci: sev']",closed,2022-01-28T05:44:27Z,2022-01-28T16:09:44Z
71974,b'Set pull_request checkout to head sha',"['module: rocm', 'cla signed', 'ciflow/default', 'ciflow/all']",open,2022-01-28T05:31:25Z,
71973,b'[UBN!] Not all tests are being run',"['high priority', 'triage review', 'module: ci', 'ci: sev']",open,2022-01-28T05:27:54Z,
71972,b'[Debugging] Fix PyTorch/XLA test failure',"['open source', 'cla signed', 'ciflow/default']",open,2022-01-28T05:22:56Z,
71971,b'[FIX] Enable TORCH_CHECK again',"['open source', 'cla signed', 'ciflow/default']",open,2022-01-28T05:17:14Z,
71970,b'Fix hooks',"['oncall: distributed', 'cla signed', 'ciflow/default']",open,2022-01-28T05:07:46Z,
71969,b'[REBASE ON MASTER] CI broken for forked pull requests',['ci: sev'],closed,2022-01-28T04:39:00Z,2022-01-28T05:38:12Z
